"""Vulnerability assessment tests for AutoTaskTracker."""
import os
import pytest
import subprocess
import json
from pathlib import Path
from unittest.mock import patch, MagicMock

from autotasktracker.config import get_config


class TestVulnerabilityAssessment:
    """Comprehensive vulnerability assessment tests."""

    def test_no_hardcoded_secrets(self):
        """Test that no hardcoded secrets exist in the codebase."""
        project_root = Path(__file__).parent.parent.parent
        
        # Common secret patterns to check for
        secret_patterns = [
            r"password\s*=\s*['\"][^'\"]{8,}['\"]",
            r"api_key\s*=\s*['\"][^'\"]{16,}['\"]",
            r"secret\s*=\s*['\"][^'\"]{16,}['\"]",
            r"token\s*=\s*['\"][^'\"]{16,}['\"]",
            r"auth\s*=\s*['\"][^'\"]{16,}['\"]"
        ]
        
        # Files to check
        python_files = list(project_root.glob("**/*.py"))
        config_files = list(project_root.glob("**/*.json")) + list(project_root.glob("**/*.yaml"))
        
        violations = []
        
        for file_path in python_files + config_files:
            if "test" in str(file_path) or "venv" in str(file_path):
                continue
                
            try:
                content = file_path.read_text()
                for pattern in secret_patterns:
                    import re
                    if re.search(pattern, content, re.IGNORECASE):
                        violations.append(f"Potential secret in {file_path}")
            except (UnicodeDecodeError, PermissionError):
                continue
        
        # Allow test database passwords and example configurations
        filtered_violations = [
            v for v in violations 
            if not any(keyword in v.lower() for keyword in ["test", "example", "sample", "demo"])
        ]
        
        assert not filtered_violations, f"Found potential hardcoded secrets: {filtered_violations}"

    def test_dependency_vulnerabilities(self):
        """Test for known vulnerabilities in dependencies."""
        try:
            # Run safety check on current dependencies
            result = subprocess.run(
                ["python", "-m", "safety", "check", "--json"],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0:
                # No vulnerabilities found
                vulnerabilities = []
            else:
                # Parse safety output
                try:
                    vulnerabilities = json.loads(result.stdout)
                except json.JSONDecodeError:
                    # Safety might output text format
                    vulnerabilities = result.stdout.split('\n') if result.stdout else []
            
            # Filter out low-severity or false positives
            critical_vulnerabilities = []
            for vuln in vulnerabilities:
                if isinstance(vuln, dict):
                    severity = vuln.get('severity', 'unknown').lower()
                    if severity in ['high', 'critical']:
                        critical_vulnerabilities.append(vuln)
                elif isinstance(vuln, str) and any(word in vuln.lower() for word in ['critical', 'high']):
                    critical_vulnerabilities.append(vuln)
            
            assert not critical_vulnerabilities, f"Critical vulnerabilities found: {critical_vulnerabilities}"
            
        except (subprocess.TimeoutExpired, FileNotFoundError):
            # Safety not available or timed out - skip test
            pytest.skip("Safety tool not available or timed out")

    def test_file_permissions(self):
        """Test that critical files have appropriate permissions."""
        project_root = Path(__file__).parent.parent.parent
        
        # Check configuration files
        config_files = [
            project_root / "autotasktracker" / "config.py",
            project_root / "setup.py"
        ]
        
        for config_file in config_files:
            if config_file.exists():
                stat = config_file.stat()
                permissions = oct(stat.st_mode)[-3:]
                
                # Should not be world-writable
                assert int(permissions[-1]) < 2, f"{config_file} is world-writable"

    def test_import_security(self):
        """Test for insecure import patterns."""
        project_root = Path(__file__).parent.parent.parent
        
        # Dangerous import patterns
        dangerous_patterns = [
            "import pickle",
            "import marshal",
            "from pickle import",
            "eval(",
            "exec(",
            "__import__"
        ]
        
        violations = []
        
        for py_file in project_root.glob("**/*.py"):
            if "test" in str(py_file) or "venv" in str(py_file):
                continue
                
            try:
                content = py_file.read_text()
                for pattern in dangerous_patterns:
                    if pattern in content:
                        # Check if it's in a comment or string
                        lines = content.split('\n')
                        for i, line in enumerate(lines):
                            if pattern in line and not line.strip().startswith('#'):
                                violations.append(f"Dangerous pattern '{pattern}' in {py_file}:{i+1}")
            except (UnicodeDecodeError, PermissionError):
                continue
        
        assert not violations, f"Found dangerous import patterns: {violations}"

    def test_sql_injection_protection(self):
        """Test for SQL injection vulnerabilities."""
        project_root = Path(__file__).parent.parent.parent
        
        # Look for potential SQL injection patterns
        sql_patterns = [
            r"execute\s*\(\s*['\"].*%.*['\"]",  # String formatting in SQL
            r"execute\s*\(\s*f['\"]",          # f-strings in SQL
            r"cursor\.execute\s*\(\s*['\"].*\+",  # String concatenation
        ]
        
        violations = []
        
        for py_file in project_root.glob("**/*.py"):
            if "test" in str(py_file) or "venv" in str(py_file):
                continue
                
            try:
                content = py_file.read_text()
                for pattern in sql_patterns:
                    import re
                    matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        violations.append(f"Potential SQL injection in {py_file}:{line_num}")
            except (UnicodeDecodeError, PermissionError):
                continue
        
        assert not violations, f"Found potential SQL injection vulnerabilities: {violations}"

    def test_path_traversal_protection(self):
        """Test for path traversal vulnerabilities."""
        project_root = Path(__file__).parent.parent.parent
        
        # Look for unsafe path operations
        unsafe_patterns = [
            r"open\s*\(\s*[^)]*\+",  # String concatenation with open()
            r"Path\s*\(\s*[^)]*\+",  # String concatenation with Path()
            r"os\.path\.join\s*\([^)]*\+",  # Concatenation with os.path.join
        ]
        
        violations = []
        
        for py_file in project_root.glob("**/*.py"):
            if "test" in str(py_file) or "venv" in str(py_file):
                continue
                
            try:
                content = py_file.read_text()
                for pattern in unsafe_patterns:
                    import re
                    matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        violations.append(f"Potential path traversal in {py_file}:{line_num}")
            except (UnicodeDecodeError, PermissionError):
                continue
        
        # Filter out false positives (like test files and safe operations)
        filtered_violations = [
            v for v in violations 
            if not any(keyword in v for keyword in ["test_", "_test", "safe", "validate"])
        ]
        
        assert not filtered_violations, f"Found potential path traversal vulnerabilities: {filtered_violations}"

    def test_environment_variable_security(self):
        """Test environment variable handling security."""
        config = get_config()
        
        # Test that sensitive environment variables are not logged
        sensitive_env_vars = [
            "DATABASE_PASSWORD",
            "API_KEY", 
            "SECRET_KEY",
            "TOKEN"
        ]
        
        for env_var in sensitive_env_vars:
            # Should not appear in normal configuration
            assert env_var not in str(config.__dict__)

    def test_temporary_file_security(self):
        """Test temporary file handling security."""
        import tempfile
        
        # Test that temporary files are created securely
        with tempfile.NamedTemporaryFile() as tmp_file:
            # Check permissions
            stat = Path(tmp_file.name).stat()
            permissions = oct(stat.st_mode)[-3:]
            
            # Should not be world-readable or world-writable
            assert int(permissions[-1]) == 0, "Temporary file is world-accessible"

    def test_logging_security(self):
        """Test that logging doesn't expose sensitive information."""
        import logging
        from io import StringIO
        
        # Capture log output
        log_capture = StringIO()
        handler = logging.StreamHandler(log_capture)
        
        # Test various loggers
        loggers = [
            logging.getLogger("autotasktracker"),
            logging.getLogger("autotasktracker.config"),
            logging.getLogger("autotasktracker.core")
        ]
        
        for logger in loggers:
            logger.addHandler(handler)
            logger.setLevel(logging.DEBUG)
        
        try:
            # Trigger some logging
            config = get_config()
            
            # Check log output
            log_output = log_capture.getvalue()
            
            # Should not contain sensitive patterns
            sensitive_patterns = [
                "password=",
                "secret=",
                "token=",
                "key="
            ]
            
            for pattern in sensitive_patterns:
                assert pattern not in log_output.lower(), f"Sensitive data '{pattern}' found in logs"
                
        finally:
            for logger in loggers:
                logger.removeHandler(handler)


class TestSecurityConfiguration:
    """Test security-related configuration."""

    def test_secure_defaults(self):
        """Test that default configuration is secure."""
        config = get_config()
        
        # Database should use secure connection if PostgreSQL
        if "postgresql://" in config.DB_PATH:
            # Should not use default/weak passwords in production
            if not os.getenv("PYTEST_CURRENT_TEST"):
                weak_passwords = ["password", "123456", "admin", "root", "test"]
                for weak_pwd in weak_passwords:
                    assert weak_pwd not in config.DB_PATH.lower()

    def test_debug_mode_security(self):
        """Test that debug mode is handled securely."""
        # Debug mode should be disabled by default
        config = get_config()
        
        # Check if debug mode is explicitly disabled
        debug_enabled = getattr(config, 'DEBUG', False)
        if not os.getenv("PYTEST_CURRENT_TEST"):
            assert not debug_enabled, "Debug mode should be disabled in production"

    def test_error_handling_security(self):
        """Test that error handling doesn't expose sensitive information."""
        from autotasktracker.core.error_handler import ErrorHandler
        
        error_handler = ErrorHandler()
        
        # Test that stack traces are sanitized in production
        try:
            raise ValueError("Test error with sensitive data: password123")
        except Exception as e:
            handled_error = error_handler.handle_error(e)
            
            # Should not contain sensitive patterns in error messages
            error_str = str(handled_error)
            assert "password123" not in error_str